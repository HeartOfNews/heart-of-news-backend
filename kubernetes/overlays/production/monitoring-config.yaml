apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-scrape-config
  labels:
    app: heart-of-news
    component: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        environment: production

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    # Load rules once and periodically evaluate them
    rule_files:
      - /etc/prometheus/rules/*.yml

    # Scrape configurations for Heart of News components
    scrape_configs:
      - job_name: 'heart-of-news-api'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: heart-of-news
        - source_labels: [__meta_kubernetes_pod_label_component]
          action: keep
          regex: api
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)

      - job_name: 'heart-of-news-worker'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_label_app]
          action: keep
          regex: heart-of-news
        - source_labels: [__meta_kubernetes_pod_label_component]
          action: keep
          regex: celery-worker
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  labels:
    app: heart-of-news
    component: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/YOUR_SLACK_WEBHOOK'
      smtp_smarthost: 'smtp.example.com:587'
      smtp_from: 'alertmanager@heartofnews.com'
      smtp_auth_username: 'alertmanager'
      smtp_auth_password: 'password'
      smtp_require_tls: true

    route:
      group_by: ['alertname', 'job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      receiver: 'team-emails'
      routes:
      - match:
          severity: critical
        receiver: 'pager-duty'
        continue: true
      - match:
          severity: warning
        receiver: 'slack-notifications'
        continue: true

    receivers:
    - name: 'team-emails'
      email_configs:
      - to: 'team@heartofnews.com'
        send_resolved: true

    - name: 'pager-duty'
      pagerduty_configs:
      - service_key: YOUR_PAGERDUTY_SERVICE_KEY
        send_resolved: true

    - name: 'slack-notifications'
      slack_configs:
      - channel: '#heart-of-news-alerts'
        send_resolved: true
        title: '[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] Heart of News Production Alert'
        text: >-
          {{ range .Alerts }}
            *Alert:* {{ .Labels.alertname }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
            *Description:* {{ .Annotations.description }}
            *Details:*
            {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
            {{ end }}
          {{ end }}